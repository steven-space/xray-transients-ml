{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Set Up Notebook and Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "import pickle\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf \n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models, losses\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Reshape, Input, Flatten, Dense, Conv2DTranspose, LeakyReLU, BatchNormalization,  LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.activations import elu\n",
    "from tensorflow.keras.initializers import HeUniform, GlorotUniform, HeNormal\n",
    "from keras.regularizers import l2, l1\n",
    "\n",
    "\n",
    "# CUSTOM Imports\n",
    "def list_folders_fun(path):\n",
    "    \"\"\"\n",
    "    DESCRIPTION: List folders in a given directory.\n",
    "    INPUT: Directory path\n",
    "    OUTPUT: Folder names in a given directory\n",
    "    \"\"\"\n",
    "    folder_list = [f.name for f in Path(path).iterdir() if f.is_dir()]\n",
    "    return folder_list\n",
    "\n",
    "# Specify global path\n",
    "global_path = '/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/0-CfA/4-Data/Datasets'\n",
    "global_folders = list_folders_fun(global_path)\n",
    "\n",
    "# Select dataset\n",
    "set_widget = widgets.Dropdown(options=global_folders[:],value=global_folders[0],description='Set :',disabled=False); set_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba19d75aba74e9fa04d3fac806ee7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='TSNE File :', options=('hist2D-Full-nE16-nt24-normminmax.pkl',), value='hist2D-Full-nE16…"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set ID\n",
    "set_id = set_widget.value\n",
    "# Select Input\n",
    "files = os.listdir(f'{global_path}/{set_id}/')\n",
    "input_files = [f for f in files if fnmatch.fnmatch(f, 'hist2D*24*minmax*')]\n",
    "input_widget = widgets.Dropdown(options=input_files[:],value=input_files[0],description='TSNE File :',disabled=False); input_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set (85925, 24, 16, 1)\n",
      "Test Set (9548, 24, 16, 1)\n",
      "Number of Features:  95473\n",
      "Number of Property Sets:  95473\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>obsreg_id</th>\n",
       "      <th>hard_hm</th>\n",
       "      <th>hard_hs</th>\n",
       "      <th>hard_ms</th>\n",
       "      <th>var_prob_b</th>\n",
       "      <th>var_prob_h</th>\n",
       "      <th>var_prob_m</th>\n",
       "      <th>var_prob_s</th>\n",
       "      <th>var_index_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2CXO J173522.0-260053</td>\n",
       "      <td>10037_123</td>\n",
       "      <td>0.354778</td>\n",
       "      <td>0.782011</td>\n",
       "      <td>0.540912</td>\n",
       "      <td>0.077612</td>\n",
       "      <td>0.092974</td>\n",
       "      <td>0.756124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2CXO J173403.7-260619</td>\n",
       "      <td>10037_30</td>\n",
       "      <td>0.564647</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.475838</td>\n",
       "      <td>0.436236</td>\n",
       "      <td>0.488032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2CXO J173412.7-260548</td>\n",
       "      <td>10037_40</td>\n",
       "      <td>0.033729</td>\n",
       "      <td>0.343535</td>\n",
       "      <td>0.312305</td>\n",
       "      <td>0.119011</td>\n",
       "      <td>0.438140</td>\n",
       "      <td>0.236688</td>\n",
       "      <td>0.551795</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2CXO J173416.8-260131</td>\n",
       "      <td>10037_79</td>\n",
       "      <td>0.352280</td>\n",
       "      <td>0.801999</td>\n",
       "      <td>0.610868</td>\n",
       "      <td>0.135159</td>\n",
       "      <td>0.314770</td>\n",
       "      <td>0.834953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2CXO J173426.3-255911</td>\n",
       "      <td>10037_81</td>\n",
       "      <td>0.548407</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.299827</td>\n",
       "      <td>0.675399</td>\n",
       "      <td>0.370636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name  obsreg_id   hard_hm   hard_hs   hard_ms  var_prob_b  \\\n",
       "0  2CXO J173522.0-260053  10037_123  0.354778  0.782011  0.540912    0.077612   \n",
       "1  2CXO J173403.7-260619   10037_30  0.564647  0.999375  0.999375    0.475838   \n",
       "2  2CXO J173412.7-260548   10037_40  0.033729  0.343535  0.312305    0.119011   \n",
       "3  2CXO J173416.8-260131   10037_79  0.352280  0.801999  0.610868    0.135159   \n",
       "4  2CXO J173426.3-255911   10037_81  0.548407  0.999375  0.999375    0.299827   \n",
       "\n",
       "   var_prob_h  var_prob_m  var_prob_s  var_index_b  \n",
       "0    0.092974    0.756124         NaN          0.0  \n",
       "1    0.436236    0.488032         NaN          0.0  \n",
       "2    0.438140    0.236688    0.551795          0.0  \n",
       "3    0.314770    0.834953         NaN          0.0  \n",
       "4    0.675399    0.370636         NaN          0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load features\n",
    "input_file = input_widget.value\n",
    "with open(f'{global_path}/{set_id}/{input_file}', 'rb') as f:\n",
    "    hist_dict = pickle.load(f)\n",
    "ids = list(hist_dict.keys())\n",
    "histograms = hist_dict.values()\n",
    "features = np.array([np.array(h) for h in histograms])\n",
    "# Load properties\n",
    "df_properties_input = pd.read_csv(f'{global_path}/{set_id}/properties-input-Full.csv')\n",
    "df_properties_input = df_properties_input[df_properties_input['obsreg_id'].isin(list(ids))]\n",
    "df_properties = df_properties_input.drop_duplicates('obsreg_id', keep='first').reset_index(drop=True)\n",
    "# Data\n",
    "df_label = df_properties.copy()\n",
    "ID = df_label['obsreg_id'].values\n",
    "X = features\n",
    "x = tf.expand_dims(X, 3)\n",
    "X_train, X_test, ID_train, ID_test = train_test_split(X, ID, test_size=0.1, random_state=42)\n",
    "x_train = tf.expand_dims(X_train, 3)\n",
    "x_test = tf.expand_dims(X_test, 3)\n",
    "# Print Summary\n",
    "print ('Training Set', x_train.shape)\n",
    "print ('Test Set', x_test.shape)\n",
    "print(\"Number of Features: \", len(features))\n",
    "print(\"Number of Property Sets: \", len(df_properties))\n",
    "\n",
    "df_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features\n",
    "input_file = input_widget.value\n",
    "with open(f'{global_path}/{set_id}/{input_file}', 'rb') as f:\n",
    "    hist_dict = pickle.load(f)\n",
    "ids = list(hist_dict.keys())\n",
    "histograms = hist_dict.values()\n",
    "features = np.array([np.array(h) for h in histograms], dtype=np.float32)\n",
    "features = torch.from_numpy(features)\n",
    "# # features = np.array([np.array(h) for h in histograms])\n",
    "# features = torch.tensor([h for h in histograms], dtype=torch.float32)\n",
    "\n",
    "# Load properties\n",
    "df_properties_input = pd.read_csv(f'{global_path}/{set_id}/properties-input-Full.csv')\n",
    "df_properties_input = df_properties_input[df_properties_input['obsreg_id'].isin(list(ids))]\n",
    "df_properties = df_properties_input.drop_duplicates('obsreg_id', keep='first').reset_index(drop=True)\n",
    "# Data\n",
    "df_label = df_properties.copy()\n",
    "ID = df_label['obsreg_id'].values\n",
    "X = torch.as_tensor(features, dtype=torch.float32)\n",
    "x = torch.unsqueeze(torch.as_tensor(X, dtype=torch.float32), 1)\n",
    "# X_train, X_test, ID_train, ID_test = train_test_split(X, ID, test_size=0.1, random_state=42)\n",
    "# x_train = torch.unsqueeze(torch.tensor(X_train), 1)\n",
    "# x_test = torch.unsqueeze(torch.tensor(X_test), 1)\n",
    "# # Print Summary\n",
    "# print ('Training Set', x_train.shape)\n",
    "# print ('Test Set', x_test.shape)\n",
    "# print(\"Number of Features: \", len(features))\n",
    "# print(\"Number of Property Sets: \", len(df_properties))\n",
    "\n",
    "# df_label.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_38 (Conv2D)          (None, 24, 16, 8)         80        \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 12, 8, 8)          264       \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 12, 8, 16)         1168      \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 6, 4, 16)          1040      \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 96)                36960     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 96)                9312      \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 24)                2328      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,152\n",
      "Trainable params: 51,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_39 (Dense)            (None, 96)                2400      \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 96)                9312      \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 96)                9312      \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 384)               37248     \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 6, 4, 16)          0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 6, 4, 16)          1040      \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 12, 8, 16)        1040      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 12, 8, 8)          1160      \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 24, 16, 8)        264       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 24, 16, 1)         73        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,849\n",
      "Trainable params: 61,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 13:56:23.552514: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-05 13:56:23.969274: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:23.969318: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:23.978672: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:23.978708: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:23.987815: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:23.987841: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:23.996800: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:23.996828: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.005712: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.005735: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.008242: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.008264: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.010705: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.010726: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.013073: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.013096: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.015506: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.015527: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.018024: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.018049: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.020425: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.020446: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.022980: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.023004: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.034236: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.034265: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.043876: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.043907: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.054261: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.054290: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.061397: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n",
      "2023-05-05 13:56:24.061422: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x7fc50253d430\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_30' defined at (most recent call last):\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/q1/jbx7qj7s0dxbh7nv02nfvc680000gn/T/ipykernel_68632/2325808267.py\", line 37, in <module>\n      history = model.fit(X_train, X_train, epochs=15,batch_size=64,shuffle=True,validation_split=0.15,callbacks=[early_stopping])\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      epochs=epochs,\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      outputs = model.train_step(data)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      force: Whether to regenerate the train function and skip the cached\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1027, in train_step\n      https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\nNode: 'StatefulPartitionedCall_30'\ncould not find registered platform with id: 0x7fc50253d430\n\t [[{{node StatefulPartitionedCall_30}}]] [Op:__inference_train_function_12277]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m encoder\u001b[39m.\u001b[39msummary()\n\u001b[1;32m     36\u001b[0m decoder\u001b[39m.\u001b[39msummary()\n\u001b[0;32m---> 37\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, X_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.15\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[early_stopping])\n\u001b[1;32m     38\u001b[0m encoder_model \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39minput, outputs\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mlayers[\u001b[39m5\u001b[39m]\u001b[39m.\u001b[39moutput)\n\u001b[1;32m     39\u001b[0m encoder_model\u001b[39m.\u001b[39mset_weights(model\u001b[39m.\u001b[39mget_weights())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_30' defined at (most recent call last):\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/q1/jbx7qj7s0dxbh7nv02nfvc680000gn/T/ipykernel_68632/2325808267.py\", line 37, in <module>\n      history = model.fit(X_train, X_train, epochs=15,batch_size=64,shuffle=True,validation_split=0.15,callbacks=[early_stopping])\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      epochs=epochs,\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      outputs = model.train_step(data)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      force: Whether to regenerate the train function and skip the cached\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1027, in train_step\n      https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\nNode: 'StatefulPartitionedCall_30'\ncould not find registered platform with id: 0x7fc50253d430\n\t [[{{node StatefulPartitionedCall_30}}]] [Op:__inference_train_function_12277]"
     ]
    }
   ],
   "source": [
    "input_shape = (24, 16, 1)\n",
    "in1 = 24\n",
    "in2 = 16\n",
    "conv_layers = 2\n",
    "conv_reduce = conv_layers ** 2\n",
    "encoder_layers = 7\n",
    "# Define encoder\n",
    "encoder = Sequential()\n",
    "encoder.add(Conv2D(8, (3, 3), activation='relu', padding='same', input_shape=input_shape)) #0\n",
    "encoder.add(Conv2D(8, (2, 2), strides = 2, activation='relu',padding='same'))\n",
    "encoder.add(Conv2D(16, (3, 3), activation='relu', padding='same'))  #2\n",
    "encoder.add(Conv2D(16, (2, 2), strides = 2, activation='relu',padding='same'))\n",
    "encoder.add(Flatten())\n",
    "encoder.add(Dense(96))\n",
    "encoder.add(Dense(96))\n",
    "encoder.add(Dense(24))\n",
    "# Define decoder\n",
    "decoder = Sequential()\n",
    "decoder.add(Dense(96, input_shape=(24,)))\n",
    "decoder.add(Dense(96))\n",
    "decoder.add(Dense(96))\n",
    "decoder.add(Dense(in1//conv_reduce*in2//conv_reduce*16))\n",
    "decoder.add(Reshape((in1//conv_reduce, in2//conv_reduce, 16)))\n",
    "decoder.add(Conv2D(16, (2, 2), activation='relu', padding='same'))\n",
    "decoder.add(Conv2DTranspose(16, (2, 2), strides = 2, activation='relu',padding='same'))\n",
    "decoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "decoder.add(Conv2DTranspose(8, (2, 2), strides = 2, activation='relu',padding='same'))\n",
    "decoder.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "# Combine encoder and decoder\n",
    "model = Sequential([encoder, decoder])\n",
    "optimizer = Adam(learning_rate = 0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=encoder_layers, verbose=1)\n",
    "loss_function = 'mse'\n",
    "model.compile(optimizer=optimizer, loss=loss_function)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "history = model.fit(X_train, X_train, epochs=15,batch_size=64,shuffle=True,validation_split=0.15,callbacks=[early_stopping])\n",
    "encoder_model = Model(inputs=model.input, outputs=model.layers[5].output)\n",
    "encoder_model.set_weights(model.get_weights())\n",
    "\n",
    "name = input('Name: ')\n",
    "model.save(f'{global_path}/{set_id}/XAE-AUTOENCODER-2D-CNN-{name}.h5')\n",
    "encoder_model.save(f'{global_path}/{set_id}/XAE-ENCODER-2D-CNN-{name}.h5')\n",
    "with open(f'{global_path}/{set_id}/XAE-HISTORY-2D-CNN-{name}.pickle', 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (20, 30) for input KerasTensor(type_spec=TensorSpec(shape=(20, 30), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, 30, 20).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/q1/jbx7qj7s0dxbh7nv02nfvc680000gn/T/__autograph_generated_fileoouzqmtq.py\", line 10, in tf__call\n        encoded = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'autoencoder_9' (type Autoencoder).\n    \n    in user code:\n    \n        File \"/var/folders/q1/jbx7qj7s0dxbh7nv02nfvc680000gn/T/ipykernel_1274/3755057309.py\", line 22, in call  *\n            encoded = self.encoder(x)\n        File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Exception encountered when calling layer 'sequential_22' (type Sequential).\n        \n        Input 0 of layer \"dense_49\" is incompatible with the layer: expected axis -1 of input shape to have value 30, but received input with shape (None, 600)\n        \n        Call arguments received by layer 'sequential_22' (type Sequential):\n          • inputs=tf.Tensor(shape=(None, 30, 20), dtype=float32)\n          • training=True\n          • mask=None\n    \n    \n    Call arguments received by layer 'autoencoder_9' (type Autoencoder):\n      • x=tf.Tensor(shape=(None, 30, 20), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m autoencoder\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39mlosses\u001b[39m.\u001b[39mMeanSquaredError())\n\u001b[1;32m     31\u001b[0m \u001b[39m# Train Autoencoder Model\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m autoencoder\u001b[39m.\u001b[39;49mfit(X_train, X_train,\n\u001b[1;32m     33\u001b[0m                 epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m     34\u001b[0m                 shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     35\u001b[0m                 validation_data\u001b[39m=\u001b[39;49m(X_test, X_test))\n\u001b[1;32m     37\u001b[0m \u001b[39m# autoencoder.fit(X_train, X_train,\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m#                 epochs=50,\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m#                 batch_size=32,\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m#                 shuffle=True,\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m#                 validation_data=(X_train, X_train),\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m#                 callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/q1/jbx7qj7s0dxbh7nv02nfvc680000gn/T/__autograph_generated_filebxfoabe7.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/q1/jbx7qj7s0dxbh7nv02nfvc680000gn/T/__autograph_generated_fileoouzqmtq.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m encoded \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mencoder, (ag__\u001b[39m.\u001b[39;49mld(x),), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[1;32m     11\u001b[0m decoded \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdecoder, (ag__\u001b[39m.\u001b[39mld(encoded),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/q1/jbx7qj7s0dxbh7nv02nfvc680000gn/T/__autograph_generated_fileoouzqmtq.py\", line 10, in tf__call\n        encoded = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'autoencoder_9' (type Autoencoder).\n    \n    in user code:\n    \n        File \"/var/folders/q1/jbx7qj7s0dxbh7nv02nfvc680000gn/T/ipykernel_1274/3755057309.py\", line 22, in call  *\n            encoded = self.encoder(x)\n        File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 277, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Exception encountered when calling layer 'sequential_22' (type Sequential).\n        \n        Input 0 of layer \"dense_49\" is incompatible with the layer: expected axis -1 of input shape to have value 30, but received input with shape (None, 600)\n        \n        Call arguments received by layer 'sequential_22' (type Sequential):\n          • inputs=tf.Tensor(shape=(None, 30, 20), dtype=float32)\n          • training=True\n          • mask=None\n    \n    \n    Call arguments received by layer 'autoencoder_9' (type Autoencoder):\n      • x=tf.Tensor(shape=(None, 30, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Define Autoencoder Model\n",
    "latent_dim = 100\n",
    "\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Input(in_shape_1,in_shape_2),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(64, activation='relu')\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(in_shape_1*in_shape_2, activation='sigmoid'),\n",
    "      layers.Reshape((in_shape_1, in_shape_2))\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "  \n",
    "autoencoder = Autoencoder(latent_dim) \n",
    "\n",
    "# Compile Autoencoder Model\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "# Train Autoencoder Model\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=20,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "# autoencoder.fit(X_train, X_train,\n",
    "#                 epochs=50,\n",
    "#                 batch_size=32,\n",
    "#                 shuffle=True,\n",
    "#                 validation_data=(X_train, X_train),\n",
    "#                 callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ciao-4.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
