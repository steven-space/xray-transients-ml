{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTHON Imports \n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "# ASTROPHY Imports\n",
    "import astropy \n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from sherpa.astro import ui\n",
    "# CIAO Imports\n",
    "import ciao_contrib.runtool\n",
    "from ciao_contrib.runtool import *\n",
    "# CUSTOM Imports\n",
    "from data_extraction_functions import *\n",
    "from data_representation_functions import *\n",
    "\n",
    "# List Folders Function\n",
    "def list_folders(path):\n",
    "    return [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n",
    "\n",
    "# Specify global path\n",
    "global_path = '/Users/steven/Desktop/Paper/'\n",
    "global_folders = list_folders_fun(global_path)\n",
    "\n",
    "# Define a custom encoder that knows how to handle NumPy arrays\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()  # convert numpy array to list\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Eventfiles:  95366\n",
      "Number of Eventfile Chunks:  151967\n"
     ]
    }
   ],
   "source": [
    "# Load eventfiles and properties\n",
    "df_eventfiles_input = pd.read_csv(f'{global_path}/eventfiles-input-sn5.csv')\n",
    "df_eventfiles_group = df_eventfiles_input.groupby('obsreg_id')\n",
    "df_chunks = df_eventfiles_input.groupby('ID')\n",
    "print(\"Number of Eventfiles: \", df_eventfiles_group.ngroups)\n",
    "print(\"Number of Eventfile Chunks: \", df_chunks.ngroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 151967 of 151967\n",
      "DONE!!!\n"
     ]
    }
   ],
   "source": [
    "# Binning Settings\n",
    "nbins_E = 16\n",
    "nbins_t = 24#24\n",
    "normalised = 'none' #'minmax' # 'none' 'minmax\n",
    "# Initialise dictionary lists\n",
    "feature_list = []\n",
    "id_list = []\n",
    "obsregid_list = []\n",
    "# Initialise counters\n",
    "count = 0\n",
    "count_limit = df_chunks.ngroups\n",
    "\n",
    "for id_name, dfi in df_chunks:\n",
    "    obsid = id_name.split(\"-\")[0]\n",
    "    regid = id_name.split(\"-\")[1]\n",
    "    obsregid = obsid + '-' + regid\n",
    "    id_list.append(id_name)\n",
    "    obsregid_list.append(obsregid)\n",
    "    #lc_plotter_fun(dfi,id_name,100)\n",
    "    #fig,axs=plt.subplots(1,3,figsize=(12,2),constrained_layout = True)\n",
    "    #plt.subplot(1, 3, 1)\n",
    "    feature_list.append(hist2D(dfi, id_name, nbins_E, nbins_t,norm = normalised,plot=False))\n",
    "    count = count+1\n",
    "    clear_output(wait=True)\n",
    "    print(f'Counter: {count} of {count_limit}')\n",
    "print(f'DONE!!!')\n",
    "\n",
    "# hist_dict = dict(zip(id_list, feature_list))\n",
    "# with open(f'{global_path}/{set_id}/histEt-{set_id}-nE{nbins_E}-nt{nbins_t}-norm{normalised}.json', 'w') as f:\n",
    "#     json.dump(hist_dict, f,cls=NumpyEncoder)\n",
    "\n",
    "hist_dict = dict(zip(id_list,feature_list))\n",
    "hist_dict2 = dict(zip(obsregid_list,feature_list))\n",
    "with open(f'{global_path}/hist2D-nE{nbins_E}-nt{nbins_t}-norm{normalised}-ID.pkl', 'wb') as f:\n",
    "    pickle.dump(hist_dict, f)\n",
    "with open(f'{global_path}/hist2D-nE{nbins_E}-nt{nbins_t}-norm{normalised}-OBSREGID.pkl', 'wb') as f:\n",
    "    pickle.dump(hist_dict2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning Settings\n",
    "nbins_E = 16 #20 #17\n",
    "nbins_t = 24#24 #30 #?25\n",
    "nbins_dt = 16 #35 #26\n",
    "normalised = 'minmax'#'minmax' \n",
    "# Initialise dictionary lists\n",
    "feature_list = []\n",
    "id_list = []\n",
    "# Initialise counters\n",
    "count = 0\n",
    "count_limit = df_chunks.ngroups\n",
    "\n",
    "for id_name, dfi in df_chunks:\n",
    "    id_list.append(id_name)\n",
    "    feature_list.append(hist3D(dfi, id_name, nbins_E, nbins_t,nbins_dt,plot=False, norm=normalised))\n",
    "    count = count+1\n",
    "    clear_output(wait=True)\n",
    "    print(f'Counter: {count} of {count_limit}')\n",
    "    print(id_name)\n",
    "    print(dfi)\n",
    "print(f'DONE!!!')\n",
    "\n",
    "\n",
    "hist_dict = dict(zip(id_list,feature_list))\n",
    "hist_dict2 = dict(zip(obsregid_list,feature_list))\n",
    "with open(f'{global_path}/hist3D-nE{nbins_E}-nt{nbins_t}-ndt{nbins_dt}-norm{normalised}-ID.pkl', 'wb') as f:\n",
    "    pickle.dump(hist_dict, f)\n",
    "with open(f'{global_path}/hist3D-nE{nbins_E}-nt{nbins_t}-ndt{nbins_dt}-norm{normalised}-OBSREGID.pkl', 'wb') as f:\n",
    "    pickle.dump(hist_dict2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       obsid  region_id  split_id          time      energy  chipx  chipy  \\\n",
      "25969  10066        155         1  3.640041e+08  1963.04650    136    666   \n",
      "25970  10066        155         1  3.640043e+08  1265.32120    146    684   \n",
      "25971  10066        155         1  3.640050e+08   941.33270    133    686   \n",
      "25972  10066        155         1  3.640053e+08   875.29346    144    682   \n",
      "25973  10066        155         1  3.640070e+08  2891.35700    126    665   \n",
      "25974  10066        155         1  3.640075e+08  1394.13510    126    672   \n",
      "25975  10066        155         1  3.640080e+08   836.64264    133    697   \n",
      "25976  10066        155         1  3.640083e+08  2002.14500    146    669   \n",
      "25977  10066        155         1  3.640084e+08  1664.65450    144    666   \n",
      "25978  10066        155         1  3.640089e+08  1824.75400    120    681   \n",
      "25979  10066        155         1  3.640112e+08   716.02200    145    667   \n",
      "25980  10066        155         1  3.640155e+08  1558.27810    128    672   \n",
      "\n",
      "       obsreg_id           ID  \n",
      "25969  10066-155  10066-155-1  \n",
      "25970  10066-155  10066-155-1  \n",
      "25971  10066-155  10066-155-1  \n",
      "25972  10066-155  10066-155-1  \n",
      "25973  10066-155  10066-155-1  \n",
      "25974  10066-155  10066-155-1  \n",
      "25975  10066-155  10066-155-1  \n",
      "25976  10066-155  10066-155-1  \n",
      "25977  10066-155  10066-155-1  \n",
      "25978  10066-155  10066-155-1  \n",
      "25979  10066-155  10066-155-1  \n",
      "25980  10066-155  10066-155-1  \n",
      "       obsid  region_id  split_id          time    energy  chipx  chipy  \\\n",
      "25981  10066        155         2  3.640636e+08  629.2594    121    673   \n",
      "\n",
      "       obsreg_id           ID  \n",
      "25981  10066-155  10066-155-2  \n"
     ]
    }
   ],
   "source": [
    "specific_group = df_chunks.get_group('10066-155-1')\n",
    "specific_group2 = df_chunks.get_group('10066-155-2')\n",
    "print(specific_group)\n",
    "print(specific_group2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11400.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.640155e+08  - 3.640041e+08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       obsid  region_id  split_id          time    energy  chipx  chipy  \\\n",
      "25981  10066        155         2  3.640636e+08  629.2594    121    673   \n",
      "\n",
      "       obsreg_id           ID  \n",
      "25981  10066-155  10066-155-2  \n"
     ]
    }
   ],
   "source": [
    "print(specific_group2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ciao_my_xspec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
