{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5b62b4bb16401a8a552c788558f1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Set :', index=1, options=('Set-2', 'Set-Y', 'Set-5', 'Set-4', 'Set-3', 'Set-6', 'Set-1')â€¦"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ciao_contrib.runtool\n",
    "from ciao_contrib.runtool import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import astropy \n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# List Folders Function\n",
    "def list_folders(path):\n",
    "    return [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n",
    "    \n",
    "# Specify path\n",
    "path = '/Users/steven/Library/CloudStorage/OneDrive-ImperialCollegeLondon/01-27-2023-FYP-CfA/4-Code-Data/Chandra-Data/'\n",
    "folders = list_folders(path)\n",
    "folder_list = []\n",
    "for folder in folders:\n",
    "    folder_list.append(folder)\n",
    "\n",
    "# Select Set\n",
    "set_widget = widgets.Dropdown(options=folder_list[:],value=folder_list[1],description='Set :',disabled=False); set_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59a6b72990e42f69c0cf66d4cb3643f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Folder :', index=1, options=('ra-5-10', 'ra-0-5'), value='ra-0-5')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set ID\n",
    "set_id = set_widget.value.split(\"-\")[1]\n",
    "# Folder List\n",
    "data_folder_path = f'/Users/steven/Library/CloudStorage/OneDrive-ImperialCollegeLondon/01-27-2023-FYP-CfA/4-Code-Data/Chandra-Data/Set-{set_id}/Data'\n",
    "data_folders = sorted(list_folders(data_folder_path))\n",
    "# Select Folder\n",
    "folder_widget = widgets.Dropdown(options=data_folders[:],value=data_folders[1],description='Folder :',disabled=False); folder_widget"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Source Region Filter Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incremental (preferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "An error occurred while running 'dmcopy':\n  Clobber set to no, and output file /Users/steven/Library/CloudStorage/OneDrive-ImperialCollegeLondon/01-27-2023-FYP-CfA/4-Code-Data/Chandra-Data/Set-Y/Data/ra-0-5/acisf08557_000N021_r0039_regevt3_filtered.fits.gz exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m region_filename \u001b[39m=\u001b[39m [region \u001b[39mfor\u001b[39;00m region \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39miglob(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdata_folder_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mfolder_id\u001b[39m}\u001b[39;00m\u001b[39m/acisf*reg3.fits.gz\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(obsid) \u001b[39min\u001b[39;00m region \u001b[39mand\u001b[39;00m \u001b[39mstr\u001b[39m(regionid) \u001b[39min\u001b[39;00m region][\u001b[39m0\u001b[39m]\n\u001b[1;32m     13\u001b[0m filtered_filename \u001b[39m=\u001b[39m event_filename\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.fits\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_filtered.fits\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m ciao_contrib\u001b[39m.\u001b[39;49mruntool\u001b[39m.\u001b[39;49mdmcopy(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mevent_filename\u001b[39m}\u001b[39;49;00m\u001b[39m[sky=region(\u001b[39;49m\u001b[39m{\u001b[39;49;00mregion_filename\u001b[39m}\u001b[39;49;00m\u001b[39m)]\u001b[39;49m\u001b[39m'\u001b[39;49m, filtered_filename)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/ciao_contrib/runtool.py:1863\u001b[0m, in \u001b[0;36mCIAOToolParFile.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1861\u001b[0m         sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1862\u001b[0m         smsg \u001b[39m=\u001b[39m sep\u001b[39m.\u001b[39mjoin(sout\u001b[39m.\u001b[39mrstrip()\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m))\n\u001b[0;32m-> 1863\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn error occurred while running \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_toolname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00msmsg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1865\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1866\u001b[0m     \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m stackfiles\u001b[39m.\u001b[39mvalues():\n",
      "\u001b[0;31mOSError\u001b[0m: An error occurred while running 'dmcopy':\n  Clobber set to no, and output file /Users/steven/Library/CloudStorage/OneDrive-ImperialCollegeLondon/01-27-2023-FYP-CfA/4-Code-Data/Chandra-Data/Set-Y/Data/ra-0-5/acisf08557_000N021_r0039_regevt3_filtered.fits.gz exists."
     ]
    }
   ],
   "source": [
    "# Set ID\n",
    "set_id = set_widget.value.split(\"-\")[1]\n",
    "# Folder ID\n",
    "folder_id = folder_widget.value\n",
    "# File Loop\n",
    "for event_filename in glob.iglob(f'{data_folder_path}/{folder_id}/acisf*regevt3*gz'):\n",
    "    obsid = int(event_filename.split('_')[0][-5:])\n",
    "    try: \n",
    "        regionid = int(event_filename.split('_')[2][-4:])\n",
    "    except: \n",
    "        regionid = int(event_filename.split('_')[3][-4:]) \n",
    "    region_filename = [region for region in glob.iglob(f'{data_folder_path}/{folder_id}/acisf*reg3.fits.gz') if str(obsid) in region and str(regionid) in region][0]\n",
    "    filtered_filename = event_filename.replace(\".fits\", \"_filtered.fits\")\n",
    "    ciao_contrib.runtool.dmcopy(f'{event_filename}[sky=region({region_filename})]', filtered_filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Loop (alternative to incremental approach, not preferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ID\n",
    "set_id = set_widget.value.split(\"-\")[1]\n",
    "# Folder List\n",
    "data_folder_path = f'/Users/steven/Library/CloudStorage/OneDrive-ImperialCollegeLondon/01-27-2023-FYP-CfA/4-Code-Data/Chandra-Data/Set-{set_id}/Data'\n",
    "data_folders = list_folders(data_folder_path)\n",
    "# Folder Loop\n",
    "for data_folder_name in data_folders:\n",
    "    # File Loop\n",
    "    for event_filename in glob.iglob(f'{data_folder_path}/{data_folder_name}/acisf*regevt3*gz'):\n",
    "        obsid = int(event_filename.split('_')[0][-5:])\n",
    "        try: \n",
    "            regionid = int(event_filename.split('_')[2][-4:])\n",
    "        except: \n",
    "            regionid = int(event_filename.split('_')[3][-4:]) \n",
    "        region_filename = [region for region in glob.iglob(f'{data_folder_path}/{data_folder_name}/acisf*reg3.fits.gz') if str(obsid) in region and str(regionid) in region][0]\n",
    "        filtered_filename = event_filename.replace(\".fits\", \"_filtered.fits\")\n",
    "        ciao_contrib.runtool.dmcopy(f'{event_filename}[sky=region({region_filename})]', filtered_filename)\n",
    "\n",
    "        print(filtered_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1 = '/Users/steven/Library/CloudStorage/OneDrive-ImperialCollegeLondon/01-27-2023-FYP-CfA/4-Code-Data/Chandra-Data/Set-Y/Data/ra-0-5/acisf11081_000N020_r0100_regevt3_filtered.fits.gz'\n",
    "# test2 = '/Users/steven/Library/CloudStorage/OneDrive-ImperialCollegeLondon/01-27-2023-FYP-CfA/4-Code-Data/Chandra-Data/Set-Y/Data/ra-0-5/acisf11081_000N020_r0100_regevt3.fits.gz'\n",
    "\n",
    "# df1 = fits.open(test1)\n",
    "# df2 = fits.open(test2)\n",
    "\n",
    "# len(df1)\n",
    "\n",
    "# with fits.open(test1) as hdul:\n",
    "#     events1 = hdul[\"Events\"].data\n",
    "#     df_events1 = pd.DataFrame.from_records(Table(events1), columns=events1.columns.names)\n",
    "\n",
    "# with fits.open(test2) as hdul:\n",
    "#     events2 = hdul[\"Events\"].data\n",
    "#     df_events2 = pd.DataFrame.from_records(Table(events2), columns=events2.columns.names)\n",
    "\n",
    "# print(len(df_events1))\n",
    "# print(len(df_events2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load and Save Event File Table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ID\n",
    "set_id = set_widget.value.split(\"-\")[1]\n",
    "# Folder ID\n",
    "folder_id = folder_widget.value\n",
    "# Initialise dataframe list of all eventfiles\n",
    "list_df_events = []\n",
    "# File Loop\n",
    "for filename in glob.iglob(f'{data_folder_path}/{folder_id}/acisf*regevt*filtered*gz'):\n",
    "  with fits.open(filename) as hdul:\n",
    "      # Events\n",
    "      events = hdul[\"Events\"].data\n",
    "      events_table = Table(events)\n",
    "      events_cols = events.columns.names\n",
    "      df_events = pd.DataFrame.from_records(events_table, columns=events_cols)\n",
    "      df_events = df_events.sort_values(by=[\"time\"])\n",
    "      # GTI (Good Time Interval)\n",
    "      gti = hdul[\"GTI\"].data\n",
    "      gti_table = Table(gti)\n",
    "      gti_cols = gti.columns.names\n",
    "      df_gti = pd.DataFrame.from_records(gti_table, columns=gti_cols)\n",
    "      # Apply GTI Filter to Events\n",
    "      gti_mask = np.zeros(len(df_events), dtype=bool)\n",
    "      for i in range(len(df_gti)):\n",
    "          start = df_gti.iloc[i]['START']\n",
    "          stop = df_gti.iloc[i]['STOP']\n",
    "          gti_mask |= (df_events[\"time\"] >= start) & (df_events[\"time\"] < stop)\n",
    "      df_events = df_events[gti_mask]\n",
    "      # Apply energy, pha, grade Filter to Events\n",
    "      df_events = df_events[(df_events['pha']>40) & (df_events['grade']>=0) & (df_events['energy']>500) & (df_events['energy']<7000)]\n",
    "      # Add obsid and region_id column (from filename)\n",
    "      df_events[\"obsid\"] = int(filename.split('_')[0][-5:])\n",
    "      try: \n",
    "        df_events[\"region_id\"] = int(filename.split('_')[2][-4:]) #need to add try except while looping \n",
    "      except: \n",
    "        df_events[\"region_id\"] = int(filename.split('_')[3][-4:]) \n",
    "      # Append to dataframe list\n",
    "      list_df_events.append(df_events)\n",
    "\n",
    "# Combine dfs in dataframe list into one df and save in folder\n",
    "df_eventfiles = pd.concat(list_df_events)\n",
    "df_eventfiles.to_csv(f'{path}Set-{set_id}/eventfiles-{set_id}-{folder_id}.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Loop (alternative to incremental approach, not preferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ID\n",
    "set_id = set_widget.value.split(\"-\")[1]\n",
    "# Initialise dataframe list of all eventfiles\n",
    "list_df_events = []\n",
    "# Folder List\n",
    "data_folder_path = f'/Users/steven/Library/CloudStorage/OneDrive-ImperialCollegeLondon/01-27-2023-FYP-CfA/4-Code-Data/Chandra-Data/Set-{set_id}/Data'\n",
    "data_folders = list_folders(data_folder_path)\n",
    "# Folder Loop\n",
    "for data_folder_name in data_folders:\n",
    "  # File Loop\n",
    "  for filename in glob.iglob(f'{data_folder_path}/{data_folder_name}/acisf*regevt*filtered*gz'):\n",
    "    with fits.open(filename) as hdul:\n",
    "        # Events\n",
    "        events = hdul[\"Events\"].data\n",
    "        events_table = Table(events)\n",
    "        events_cols = events.columns.names\n",
    "        df_events = pd.DataFrame.from_records(events_table, columns=events_cols)\n",
    "        df_events = df_events.sort_values(by=[\"time\"])\n",
    "        # GTI (Good Time Interval)\n",
    "        gti = hdul[\"GTI\"].data\n",
    "        gti_table = Table(gti)\n",
    "        gti_cols = gti.columns.names\n",
    "        df_gti = pd.DataFrame.from_records(gti_table, columns=gti_cols)\n",
    "        # Apply GTI Filter to Events\n",
    "        gti_mask = np.zeros(len(df_events), dtype=bool)\n",
    "        for i in range(len(df_gti)):\n",
    "            start = df_gti.iloc[i]['START']\n",
    "            stop = df_gti.iloc[i]['STOP']\n",
    "            gti_mask |= (df_events[\"time\"] >= start) & (df_events[\"time\"] < stop)\n",
    "        df_events = df_events[gti_mask]\n",
    "        # Apply energy, pha, grade Filter to Events\n",
    "        df_events = df_events[(df_events['pha']>40) & (df_events['grade']>=0) & (df_events['energy']>500) & (df_events['energy']<7000)]\n",
    "        # Add obsid and region_id column (from filename)\n",
    "        df_events[\"obsid\"] = int(filename.split('_')[0][-5:])\n",
    "        try: \n",
    "          df_events[\"region_id\"] = int(filename.split('_')[2][-4:]) #need to add try except while looping \n",
    "        except: \n",
    "          df_events[\"region_id\"] = int(filename.split('_')[3][-4:]) \n",
    "        # Append to dataframe list\n",
    "        list_df_events.append(df_events)\n",
    "\n",
    "# Combine dfs in dataframe list into one df and save in folder\n",
    "df_eventfiles = pd.concat(list_df_events)\n",
    "df_eventfiles.to_csv(f'{path}Set-{set_id}/eventfiles-{set_id}.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Concatenate Eventfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pr/pzfn3sxs66jfxwx55jdxqrd00000gn/T/ipykernel_13524/1331119868.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_labels['obsreg_id'] = df_labels['obsid'].astype(str) + '_' + df_labels['region_id'].astype(str)\n",
      "/var/folders/pr/pzfn3sxs66jfxwx55jdxqrd00000gn/T/ipykernel_13524/1331119868.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_input['obsreg_id'] = df_input['obsid'].astype(str) + '_' + df_input['region_id'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Set ID\n",
    "set_id = set_widget.value.split(\"-\")[1]\n",
    "# Folder ID\n",
    "folder_id = folder_widget.value\n",
    "# Load Eventfiles Table\n",
    "df_events_list=[]\n",
    "for evtfile_name in os.listdir(f'{path}Set-{set_id}/'):\n",
    "    if evtfile_name.startswith(f'eventfiles-{set_id}-ra'):\n",
    "        df_evt = pd.read_csv(f'{path}Set-{set_id}/{evtfile_name}')\n",
    "        df_events_list.append(df_evt)\n",
    "df_evt = pd.concat(df_events_list)\n",
    "df_evt.to_csv(f'{path}Set-{set_id}/eventfiles-{set_id}.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generate Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pr/pzfn3sxs66jfxwx55jdxqrd00000gn/T/ipykernel_13524/2929536628.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_labels['obsreg_id'] = df_labels['obsid'].astype(str) + '_' + df_labels['region_id'].astype(str)\n",
      "/var/folders/pr/pzfn3sxs66jfxwx55jdxqrd00000gn/T/ipykernel_13524/2929536628.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_input['obsreg_id'] = df_input['obsid'].astype(str) + '_' + df_input['region_id'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Set ID\n",
    "set_id = set_widget.value.split(\"-\")[1]\n",
    "# Folder ID\n",
    "folder_id = folder_widget.value\n",
    "# Load Properties Table\n",
    "df_prop = pd.read_csv(f'{path}Set-{set_id}/properties-{set_id}.csv')\n",
    "# Load Properties Table\n",
    "df_events = pd.read_csv(f'{path}Set-{set_id}/eventfiles-{set_id}.csv')\n",
    "# Extract important labels and input columns\n",
    "df_labels = df_prop[['obsid','region_id','cnts_aper_b','cnts_aperbkg_b','src_cnts_aper_b','flux_aper_b','hard_hm','hard_hs','hard_ms','var_prob_b','var_prob_h','var_prob_m','var_prob_s']]\n",
    "df_input = df_events[['obsid','region_id','time','energy','chipx','chipy']]\n",
    "# Make Sure Eventfile Table only includes information contained in Properties Table and vice versa\n",
    "df_labels['obsreg_id'] = df_labels['obsid'].astype(str) + '_' + df_labels['region_id'].astype(str)\n",
    "df_input['obsreg_id'] = df_input['obsid'].astype(str) + '_' + df_input['region_id'].astype(str)\n",
    "df_labels = df_labels[df_labels['obsreg_id'].isin(df_input['obsreg_id'].unique())]\n",
    "df_input = df_input[df_input['obsreg_id'].isin(df_labels['obsreg_id'].unique())]\n",
    "# Save ungrouped tables\n",
    "df_labels.to_csv(f'{path}Set-{set_id}/labels-{set_id}.csv',index=False)\n",
    "df_input.to_csv(f'{path}Set-{set_id}/input-{set_id}.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ciao-4.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6d43af9514cdee395f25bb9cf426d32ed46b72652151f60ea91d2ee58eae181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
