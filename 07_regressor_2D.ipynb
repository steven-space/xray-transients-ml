{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Set Up Notebook and Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 17:40:55.923678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ce04f7466c4a06a6de219568fb002d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Set :', options=('All', 'Bona'), value='All')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PYTHON Imports \n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "\n",
    "import umap\n",
    "import seaborn as sns\n",
    "import fnmatch\n",
    "# ML Imports\n",
    "import tensorflow as tf\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "# ASTROPHY Imports\n",
    "import astropy \n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from sherpa.astro import ui\n",
    "# CIAO Imports\n",
    "import ciao_contrib.runtool\n",
    "from ciao_contrib.runtool import *\n",
    "# CUSTOM Imports\n",
    "from data_extraction_functions import *\n",
    "from data_exploration_functions import *\n",
    "from data_representation_functions import *\n",
    "\n",
    "# Specify global path\n",
    "global_path = '/Users/steven/Library/Mobile Documents/com~apple~CloudDocs/0-CfA/4-Data/Datasets'\n",
    "global_folders = list_folders_fun(global_path)\n",
    "\n",
    "# Select dataset\n",
    "set_widget = widgets.Dropdown(options=global_folders[:],value=global_folders[0],description='Set :',disabled=False); set_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e049d1b8ec44448b7894bd3f98305ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='TSNE File :', options=('hist2D-All-nE20-nt30-normnone.pkl',), value='hist2D-All-nE20-nt3â€¦"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set ID\n",
    "set_id = set_widget.value\n",
    "# Select Input\n",
    "files = os.listdir(f'{global_path}/{set_id}/')\n",
    "input_files = [f for f in files if fnmatch.fnmatch(f, 'hist2D*')]\n",
    "input_widget = widgets.Dropdown(options=input_files[:],value=input_files[0],description='TSNE File :',disabled=False); input_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features:  82283\n",
      "Number of Property Sets:  82283\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnts_aper_b</th>\n",
       "      <th>cnts_aperbkg_b</th>\n",
       "      <th>src_cnts_aper_b</th>\n",
       "      <th>flux_aper_b</th>\n",
       "      <th>hard_hm</th>\n",
       "      <th>hard_hs</th>\n",
       "      <th>hard_ms</th>\n",
       "      <th>var_prob_b</th>\n",
       "      <th>var_prob_h</th>\n",
       "      <th>var_prob_m</th>\n",
       "      <th>var_prob_s</th>\n",
       "      <th>obsreg_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>38</td>\n",
       "      <td>68.744294</td>\n",
       "      <td>5.470823e-13</td>\n",
       "      <td>0.223610</td>\n",
       "      <td>0.745784</td>\n",
       "      <td>0.618364</td>\n",
       "      <td>0.310792</td>\n",
       "      <td>0.117484</td>\n",
       "      <td>0.675801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10003_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "      <td>55.350611</td>\n",
       "      <td>5.470823e-13</td>\n",
       "      <td>0.398501</td>\n",
       "      <td>0.488445</td>\n",
       "      <td>0.094941</td>\n",
       "      <td>0.524820</td>\n",
       "      <td>0.127010</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.485168</td>\n",
       "      <td>10004_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>28</td>\n",
       "      <td>41.900915</td>\n",
       "      <td>4.311669e-13</td>\n",
       "      <td>0.873204</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.765525</td>\n",
       "      <td>0.888159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10018_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144</td>\n",
       "      <td>1354</td>\n",
       "      <td>94.226698</td>\n",
       "      <td>5.097861e-14</td>\n",
       "      <td>0.058713</td>\n",
       "      <td>-0.103685</td>\n",
       "      <td>-0.162399</td>\n",
       "      <td>0.105254</td>\n",
       "      <td>0.252282</td>\n",
       "      <td>0.650681</td>\n",
       "      <td>0.283007</td>\n",
       "      <td>10025_72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202</td>\n",
       "      <td>2417</td>\n",
       "      <td>118.341424</td>\n",
       "      <td>7.185242e-14</td>\n",
       "      <td>0.339788</td>\n",
       "      <td>0.678326</td>\n",
       "      <td>0.413492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10025_74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cnts_aper_b  cnts_aperbkg_b  src_cnts_aper_b   flux_aper_b   hard_hm  \\\n",
       "0           66              38        68.744294  5.470823e-13  0.223610   \n",
       "1           53              20        55.350611  5.470823e-13  0.398501   \n",
       "2           39              28        41.900915  4.311669e-13  0.873204   \n",
       "3          144            1354        94.226698  5.097861e-14  0.058713   \n",
       "4          202            2417       118.341424  7.185242e-14  0.339788   \n",
       "\n",
       "    hard_hs   hard_ms  var_prob_b  var_prob_h  var_prob_m  var_prob_s  \\\n",
       "0  0.745784  0.618364    0.310792    0.117484    0.675801         NaN   \n",
       "1  0.488445  0.094941    0.524820    0.127010    0.676527    0.485168   \n",
       "2  0.999375  0.999375    0.765525    0.888159         NaN         NaN   \n",
       "3 -0.103685 -0.162399    0.105254    0.252282    0.650681    0.283007   \n",
       "4  0.678326  0.413492         NaN    0.650170         NaN         NaN   \n",
       "\n",
       "  obsreg_id  \n",
       "0   10003_2  \n",
       "1   10004_1  \n",
       "2   10018_1  \n",
       "3  10025_72  \n",
       "4  10025_74  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the DataFrame from the CSV file\n",
    "input_file = input_widget.value\n",
    "# Load histogram dictionary\n",
    "with open(f'{global_path}/{set_id}/{input_file}', 'rb') as f:\n",
    "    hist_dict = pickle.load(f)\n",
    "# Flatten histograms in the dictionary and get IDs\n",
    "ids = hist_dict.keys()\n",
    "histograms = hist_dict.values()\n",
    "features = np.array([np.array(h) for h in histograms])\n",
    "#features[np.isnan(features)] = 0.0\n",
    "# Load properties\n",
    "df_properties_input = pd.read_csv(f'{global_path}/{set_id}/properties-input-{set_id}.csv')\n",
    "df_properties_input = df_properties_input[df_properties_input['obsreg_id'].isin(list(ids))]\n",
    "df_properties = df_properties_input.drop_duplicates('obsreg_id', keep='first').reset_index(drop=True)\n",
    "# Print eventfiles and properties number of IDs\n",
    "print(\"Number of Features: \", len(features))\n",
    "print(\"Number of Property Sets: \", len(df_properties))\n",
    "\n",
    "df_properties.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "df_label = df_properties.copy()\n",
    "mask_nonan = df_label.notna().all(axis=1)\n",
    "index_nonan = list(df_label.notna().all(axis=1).index[df_label.notna().all(axis=1)])\n",
    "df_label = df_label[mask_nonan]\n",
    "ID = df_label['obsreg_id'].values\n",
    "X = np.array([features[i] for i in index_nonan])\n",
    "# X = X/np.max(X)\n",
    "hr_hm = np.array(df_label['hard_hm'].values)\n",
    "hr_hs = np.array(df_label['hard_hs'].values)\n",
    "hr_ms = np.array(df_label['hard_ms'].values)\n",
    "var_h = np.array(df_label['var_prob_h'].values)\n",
    "var_m = np.array(df_label['var_prob_m'].values)\n",
    "var_s = np.array(df_label['var_prob_s'].values)\n",
    "var_b = np.array(df_label['var_prob_b'].values)\n",
    "# Split into training and test data\n",
    "X_train, X_test, hr_hm_train, hr_hm_test, hr_hs_train, hr_hs_test, hr_ms_train, hr_ms_test, var_h_train, var_h_test, var_m_train, var_m_test, var_s_train, var_s_test, var_b_train, var_b_test = train_test_split(X, hr_hm, hr_hs, hr_ms, var_h, var_m, var_s, var_b, test_size=0.2, random_state=42)\n",
    "# Define Input Shape\n",
    "in_shape = X[0].shape\n",
    "in_shape_1 = in_shape[0]\n",
    "in_shape_2 = in_shape[1]\n",
    "# Reshape data to 4D tensor for use with CNN\n",
    "X_train = X_train.reshape(X_train.shape[0], in_shape_1, in_shape_2, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], in_shape_1, in_shape_2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 17:42:04.311150: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 17:42:04.313881: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-12 17:42:04.314259: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "# Define your CNN architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(in_shape_1,in_shape_2, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(7)  # one output for each label\n",
    "])\n",
    "\n",
    "# Compile your model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1028, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1122, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 577, in update_state\n        self.build(y_pred, y_true)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 483, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 631, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 631, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 652, in _get_metric_object\n        y_t_rank = len(y_t.shape.as_list())\n\n    AttributeError: 'tuple' object has no attribute 'shape'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train your model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, [hr_hm_train, hr_hs_train, hr_ms_train, var_h_train, var_m_train, var_s_train, var_b_train],\n\u001b[1;32m      3\u001b[0m           epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/q1/jbx7qj7s0dxbh7nv02nfvc680000gn/T/__autograph_generated_filejar_4yyj.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1028, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/training.py\", line 1122, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 577, in update_state\n        self.build(y_pred, y_true)\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 483, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 631, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 631, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/opt/anaconda3/envs/ciao-4.15/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 652, in _get_metric_object\n        y_t_rank = len(y_t.shape.as_list())\n\n    AttributeError: 'tuple' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "# Train your model\n",
    "model.fit(X_train, [hr_hm_train, hr_hs_train, hr_ms_train, var_h_train, var_m_train, var_s_train, var_b_train],\n",
    "          epochs=10, batch_size=32, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ciao-4.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
